{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f29c85",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "In this issue, we will learn an another algorithm linear classification - soft output - probability generation model: Naive Bayes Hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090cfdb",
   "metadata": {},
   "source": [
    "## Idea\n",
    "In the last issue, $GDA$ we learned makes an assumption that the dataset obeys Gaussian Dist. At the same time, Bernoulli Dist is introduced as a priori of the label to obtain the parameters via $MAP$.\n",
    "\n",
    "Naive Bayes Hypothesis we learned in this issue assumes the relationship between the attributes of the data: the conditional independence hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef8ee7",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097aee9",
   "metadata": {},
   "source": [
    "Normally, since there is $p$ dimensions in $x$, we need to sample the joint distribution of $p$ random variables to get the probability $p(x|y)$. However, as we know: A huge number of samples are needed to obtain the relative accurate probability approximation as to the high-dimensional space.\n",
    "\n",
    "In the general directed probability graph model, different assumptions are made on the conditional independence relationship between various attribute dimensions, among which the simplest assumption is that one described in Naive Bayes model:\n",
    "$$\n",
    "p(x|y)=\\prod_{i=1}^p p(x_i|y)p(y)\n",
    "$$\n",
    "In mathematical language:\n",
    "$$\n",
    "x_{i} \\perp x_{j} | y, \\forall i \\neq j\n",
    "$$\n",
    "for a simple observation with Bayesian theorem:\n",
    "$$\n",
    "p(y|x)=\\frac{p(x|y)p(y)}{p(x)}=\\frac{\\prod_{i=1}^p p(x_i|y)p(y)}{p(x)}\n",
    "$$\n",
    "Similar to $GDA$, here are some assumptions about the distributions of the data:\n",
    "* $x_i$ is a discrete variable:\n",
    "   * Generally, we assume $x_i$ obey Categorical Dist: $p(x_i=i|y)=\\theta_i,\\sum_{i=1}^p \\theta_i =1$\n",
    "\n",
    "* $x_i$ is a continuous variable:\n",
    "   * Generally, we assume $x_i$ obey Gaussian Dist: $p(x_i|y)=N(\\mu_i, \\Sigma_i)$\n",
    "* Binary classification:\n",
    "    * $y \\sim Bernoulli(\\phi):p(y)=\\phi^y (1-\\phi)^{(1-y)}$ \n",
    "* Multi-classification:\n",
    "    * $y \\sim Categorical\\ Dist\\quad p(y_i)=\\theta_i\\quad \\sum_{i=1}^k \\theta_i=1$\n",
    "\n",
    "We are used to sample the dataset to estimate the parameters. we'll obtain the posteriori probability with Bayesian theorem when we are to predict test data after estimating the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb557c",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fedb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([6.763511927008758, 0.0676351192700876], [4.499499499499499, 1.44994994994995], [6.763511927008758, 0.6087160734307883], [4.499499499499499, 3.34984984984985])\n",
      "accuary: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "from models.linear_models import NaiveBayesClassifier\n",
    "\n",
    "num_test = 100\n",
    "x = np.linspace(0, 10, 1000)\n",
    "k1, k2 = 0.1, 0.3\n",
    "b1, b2 = 1, 2\n",
    "x_train = x[:-num_test]\n",
    "x_test = x[-num_test:]\n",
    "v_1 = x_train * k1 + b1\n",
    "v_2 = x_train * k2 + b2\n",
    "train_data = np.r_[np.c_[x_train, v_1], np.c_[x_train, v_2]]\n",
    "train_label = np.r_[np.ones_like(x_train), np.zeros_like(x_train)]\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.fit(train_data, train_label)\n",
    "print(model.get_params())\n",
    "\n",
    "v_test = x_test * k2 + b2\n",
    "data_test = np.c_[x_test, v_test]\n",
    "print(\"accuary:\", model.predict(data_test, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
