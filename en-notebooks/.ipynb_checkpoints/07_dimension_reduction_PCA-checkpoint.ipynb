{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0faba8bc",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "In this issue, we begin to learn the algorithm of dimension reduction.\n",
    "\n",
    "As we know, dimension reduction is the best way to solve the problem of over fitting, in addition to increasing data and regularization.\n",
    "\n",
    "In fact, the predecessors had encountered dimensional disasters earlier. We know that the volume of the $n $ dimensional sphere is\n",
    "$$\n",
    "CR^n\n",
    "$$\n",
    "Therefore, the ratio of the volume of the sphere to the $n$ dimensional hypercube is\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\lim_{n&space;\\to&space;&plus;\\infty}=\\frac{CR^n}{2^n&space;R^n}=0\" title=\"\\lim_{n \\to +\\infty}=\\frac{CR^n}{2^n R^n}=0\" />\n",
    "From the formula, we can see that in high-dimensional data, the distribution of samples is quite sparse, and the interior of hypercube is almost hollow, so it is more difficult to model the data. This is the so-called dimensional disaster.\n",
    "\n",
    "The dimensionality reduction methods are divided into:\n",
    "* Direct dimensionality reduction, feature selection\n",
    "* Linear dimensionality reduction, $PCA$，$MDS$等\n",
    "* Piecewise linear, manifolds include $Isomap$, $LLE$ etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bfefe",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13294d04",
   "metadata": {},
   "source": [
    "As for the core idea of $PCA$, the teacher summarized a line: one center, two basic points\n",
    "* one center:\n",
    "    * to transform each feature that may be linearly related into a set of linearly independent features via an orthogonal transformation.\n",
    "    * That is, to reconstruct the original feature space.\n",
    "* Two basic points:\n",
    "    * Maximum Projection Variance\n",
    "        * Make the data more dispersed in the reconstructed feature space (because the original data is clustered together and scattered in corners)\n",
    "    * Minimum Reconfiguration Distance\n",
    "        * to minimize the loss of information (i.e., fewer components of the complementary space) after the data has been reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e236c6",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "we'll mainly talk about the first basic point: maximum projection variance. In fact, the two basic points mean the same thing, but interpret a center from different angles.\n",
    "\n",
    "Firstly,we are to review the projection. We have talked about projection before, and the same is true here. Let's assume sample $x_ i $, a base vector $u_ i $, assuming $u_ i^Tu_ i = 1 $, so you can get the projection of the sample in  this dimension $u_ i $ is\n",
    "$$\n",
    "project_i=x_i^Tu_i\n",
    "$$\n",
    "After orthogonal transformation, the sample originally has $p $ feature dimensions. Because we need to reduce the dimension, we only take the first $q $ features, and these $q $ features are linearly independent. Therefore, these projections can be directly added to obtain the projection of the sample in the new feature space.\n",
    "\n",
    "Note that the data is centered before the projection, so the mean value of the data is changed to zero, and the variance of the projection can be squared directly.\n",
    "\n",
    "To sum up, we get the objective function:\n",
    "$$\n",
    "J=\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{q}\\left(\\left(x_{i}-\\bar{x}\\right)^{T} u_{j}\\right)^{2}\n",
    "$$\n",
    "The objective function is derived slightly below:\n",
    "\n",
    "since the shape of $((x_i-\\bar{x})^Tu_j)$ is $(1,p)* (p,1)=(1,1)$, therefore, it can be transposed:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "J&=\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{q}\\left(\\left(x_{i}-\\bar{x}\\right)^{T} u_{j}\\right)^{2}\\\\\n",
    "&=\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{q}(u_{j}^T(x_{i}-\\bar{x}))^{2}\\\\\n",
    "&=\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{q}u_{j}^T(x_{i}-\\bar{x}))(x_{i}-\\bar{x})^T u_j\\\\\n",
    "&=\\sum_{j=1}^{q} u_{j}^T(\\frac{1}{N} \\sum_{i=1}^{N} (x_{i}-\\bar{x}))(x_{i}-\\bar{x})^T) u_j\\\\\n",
    "&=\\sum_{j=1}^q u_j^T S u_j\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Don't forget that we have another condition: $s.t\\ u_j^T u_j=1$\n",
    "\n",
    "So you can use Lagrange multiplier:\n",
    "<img src=\"https://latex.codecogs.com/svg.image?\\underset{u_{j}}{\\operatorname{argmax}}&space;L\\left(u_{j},&space;\\lambda\\right)=\\underset{u_{j}}{\\operatorname{argmax}}&space;u_{j}^{T}&space;S&space;u_{j}&plus;\\lambda\\left(1-u_{j}^{T}&space;u_{j}\\right)\" title=\"\\underset{u_{j}}{\\operatorname{argmax}} L\\left(u_{j}, \\lambda\\right)=\\underset{u_{j}}{\\operatorname{argmax}} u_{j}^{T} S u_{j}+\\lambda\\left(1-u_{j}^{T} u_{j}\\right)\" />\n",
    "To derive from the above:\n",
    "$$\n",
    "\\frac{\\partial \\Delta}{\\partial u_j}=2S u_j -2\\lambda u_j=0\n",
    "$$\n",
    "we get:\n",
    "$$\n",
    "S u_j = \\lambda u_j\n",
    "$$\n",
    "You can see that the transformed base vector is actually the eigenvector of the covariance matrix, $\\lambda$ is the eigenvalue of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf8682",
   "metadata": {},
   "source": [
    "In fact, the solution of covariance matrices can also be simplified:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "S &=\\frac{1}{N} \\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}\\right)\\left(x_{i}-\\bar{x}\\right)^{T} \\\\\n",
    "&=\\frac{1}{N}\\left(x_{1}-\\bar{x}, x_{2}-\\bar{x}, \\cdots, x_{N}-\\bar{x}\\right)\\left(x_{1}-\\bar{x}, x_{2}-\\bar{x}, \\cdots, x_{N}-\\bar{x}\\right)^{T} \\\\\n",
    "&=\\frac{1}{N}\\left(X^{T}-\\frac{1}{N} X^{T} I_{N} I_{N}^{T}\\right)\\left(X^{T}-\\frac{1}{N} X^{T} I_{N} I_{N}^{T}\\right)^{T} \\\\\n",
    "&=\\frac{1}{N} X^{T}\\left(E_{N}-\\frac{1}{N} I_{N} I_{N}^T\\right)\\left(E_{N}-\\frac{1}{N} I_{N} I_{N}^T\\right)^{T} X \\\\\n",
    "&=\\frac{1}{N} X^{T} H_{N} H_{N}^{T} X \\\\\n",
    "&=\\frac{1}{N} X^{T} H_{N} H_{N} X=\\frac{1}{N} X^{T} H X\n",
    "\\end{aligned}\n",
    "$$\n",
    "Here, $H$ is a special matrix, called a central matrix.\n",
    "$$\n",
    "H=E_N - \\frac{1}{N}I_N I_N^T\n",
    "$$\n",
    "Therefore, in practice, we only need to find the covariance matrix using the above formula, and then decompose it orthogonally to get the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498fc468",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb846c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "from models.decompose_models import PCA\n",
    "\n",
    "k, b = 3, 4\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = x * k + b\n",
    "x += np.random.normal(scale=0.3, size=x.shape)\n",
    "data = np.c_[x, y]\n",
    "\n",
    "model = PCA()\n",
    "model.fit(data)\n",
    "model.draw(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
